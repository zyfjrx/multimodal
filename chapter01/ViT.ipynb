{
 "cells": [
  {
   "cell_type": "code",
   "id": "172195ed-ea05-4af2-8c3b-16c5268a237b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T01:32:34.903947Z",
     "start_time": "2025-10-16T01:32:32.942123Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as T\n",
    "from torch.optim import Adam\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "fd3eb734-e8c0-4e1f-9460-f335b6fe9e7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T01:32:37.170955Z",
     "start_time": "2025-10-16T01:32:37.166760Z"
    }
   },
   "source": [
    "class PatchEmbedding(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_model,    # 模型的维度\n",
    "        img_size,   # 图片大小\n",
    "        patch_size, # 补丁大小\n",
    "        n_channels  # 通道数量\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.img_size = img_size\n",
    "        self.patch_size = patch_size\n",
    "        self.n_channels = n_channels\n",
    "\n",
    "        self.linear_project = nn.Conv2d(\n",
    "            self.n_channels, # in_channels\n",
    "            self.d_model, # out_channels\n",
    "            kernel_size=self.patch_size, # kernel_size\n",
    "            stride=self.patch_size # stride\n",
    "        )\n",
    "\n",
    "    # B: 批次大小\n",
    "    # C: 通道数量\n",
    "    # H: 图像高度\n",
    "    # W: 图像宽度\n",
    "    # P_col: 补丁的列\n",
    "    # P_row: 补丁的行\n",
    "    def forward(self, x):\n",
    "        x = self.linear_project(x)\n",
    "        #(B, C, H, W) -> (B, d_model, P_col, P_row)\n",
    "        # d_model是每个补丁的嵌入维度3x16x16=768\n",
    "        # print(x)\n",
    "        x = x.flatten(2) #拉成一维\n",
    "        # (B, d_model, P_col, P_row) -> (B, d_model, P)\n",
    "        x = x.transpose(1, 2) #转置\n",
    "        return x"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "62a2313a-01f0-43ed-a29e-78d3fa057d27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T01:32:40.120691Z",
     "start_time": "2025-10-16T01:32:40.115908Z"
    }
   },
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_length):\n",
    "        super().__init__()\n",
    "        # 类别token\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, d_model))\n",
    "        # 创建位置编码\n",
    "        pe = torch.zeros(max_seq_length, d_model)\n",
    "\n",
    "        for pos in range(max_seq_length):\n",
    "            for i in range(d_model):\n",
    "                if i % 2 == 0:\n",
    "                    pe[pos][i] = np.sin(pos/(10000 ** (i/d_model)))\n",
    "                else:\n",
    "                    pe[pos][i] = np.cos(pos/(10000 ** ((i-1)/d_model)))\n",
    "\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 为批次中的每张图片分配一个类别token\n",
    "        tokens_batch = self.cls_token.expand(x.size()[0], -1, -1)\n",
    "        # 将类别token添加到每个图像的补丁嵌入数组的开头\n",
    "        x = torch.cat((tokens_batch,x), dim=1)\n",
    "        # 将位置编码添加到嵌入中\n",
    "        x = x + self.pe\n",
    "        return x"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "a252c8c4-2513-4380-a713-f4b206c3c263",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T01:32:42.839785Z",
     "start_time": "2025-10-16T01:32:42.835924Z"
    }
   },
   "source": [
    "class AttentionHead(nn.Module):\n",
    "    def __init__(self, d_model, head_size):\n",
    "        super().__init__()\n",
    "        self.head_size = head_size\n",
    "\n",
    "        self.query = nn.Linear(d_model, head_size)\n",
    "        self.key = nn.Linear(d_model, head_size)\n",
    "        self.value = nn.Linear(d_model, head_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 计算Q, K, V\n",
    "        Q = self.query(x)\n",
    "        K = self.key(x)\n",
    "        V = self.value(x)\n",
    "\n",
    "        # Q和K的点积\n",
    "        attention = Q @ K.transpose(-2,-1)\n",
    "\n",
    "        # 缩放\n",
    "        attention = attention / (self.head_size ** 0.5)\n",
    "        attention = torch.softmax(attention, dim=-1)\n",
    "        attention = attention @ V\n",
    "\n",
    "        return attention"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "39cedd52-a92c-4b93-86a8-1765bd9723ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T01:32:45.692712Z",
     "start_time": "2025-10-16T01:32:45.689066Z"
    }
   },
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, n_heads):\n",
    "        super().__init__()\n",
    "        self.head_size = d_model // n_heads\n",
    "        self.W_o = nn.Linear(d_model, d_model)\n",
    "        self.heads = nn.ModuleList([\n",
    "            AttentionHead(d_model, self.head_size) for _ in range(n_heads)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 拼接多个注意力头\n",
    "        out = torch.cat([head(x) for head in self.heads], dim=-1)\n",
    "        out = self.W_o(out)\n",
    "        return out"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "012f9dee-46bc-46a2-a9ae-3a8d1c02f1f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T01:32:47.545959Z",
     "start_time": "2025-10-16T01:32:47.541996Z"
    }
   },
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, r_mlp=4):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "        # 层归一化\n",
    "        self.ln1 = nn.LayerNorm(d_model)\n",
    "\n",
    "        # 多头注意力\n",
    "        self.mha = MultiHeadAttention(d_model, n_heads)\n",
    "\n",
    "        # 层归一化\n",
    "        self.ln2 = nn.LayerNorm(d_model)\n",
    "\n",
    "        # MLP\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model*r_mlp),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(d_model*r_mlp, d_model)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 第一次层归一化之后的残差\n",
    "        out = x + self.mha(self.ln1(x))\n",
    "        # 第二次层归一化之后的残差\n",
    "        out = out + self.mlp(self.ln2(out))\n",
    "        return out"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "f99135a5-f294-461f-b302-3435bba69eaa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T01:32:50.784577Z",
     "start_time": "2025-10-16T01:32:50.778581Z"
    }
   },
   "source": [
    "class VisionTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_model,\n",
    "        n_classes,\n",
    "        img_size,\n",
    "        patch_size,\n",
    "        n_channels,\n",
    "        n_heads,\n",
    "        n_layers\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        assert img_size[0] % patch_size[0] == 0  \\\n",
    "           and img_size[1] % patch_size[1] == 0, \\\n",
    "           \"img_size 必须能被 patch_size 整除\"\n",
    "        assert d_model % n_heads == 0, \\\n",
    "           \"d_model 必须能被 n_heads 整除\"\n",
    "\n",
    "        self.d_model = d_model # 模型维度，嵌入的维度（宽度）\n",
    "        self.n_classes = n_classes # 类别的数量\n",
    "        self.img_size = img_size # 图片大小\n",
    "        self.patch_size = patch_size # 补丁大小\n",
    "        self.n_channels = n_channels # 通道数\n",
    "        self.n_heads = n_heads # 注意力头的数量\n",
    "        # 补丁的数量 = (32x32) // (4x4)\n",
    "        self.n_patches = (self.img_size[0] * self.img_size[1]) \\\n",
    "                      // (self.patch_size[0] * self.patch_size[1])\n",
    "        # 序列的长度 = 1（分类token） + 补丁的数量\n",
    "        self.max_seq_length = self.n_patches + 1\n",
    "        # 补丁嵌入\n",
    "        self.patch_embedding = PatchEmbedding(\n",
    "            self.d_model,\n",
    "            self.img_size,\n",
    "            self.patch_size,\n",
    "            self.n_channels\n",
    "        )\n",
    "        # 位置编码\n",
    "        self.positional_encoding = PositionalEncoding(\n",
    "            self.d_model,\n",
    "            self.max_seq_length\n",
    "        )\n",
    "        self.transformer_encoder = nn.Sequential(*[\n",
    "            TransformerEncoder(self.d_model, self.n_heads)\n",
    "            for _ in range(n_layers)\n",
    "        ])\n",
    "\n",
    "        # 用于分类的MLP\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.d_model, self.n_classes),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "\n",
    "    def forward(self, images):\n",
    "        # 将图片转换成补丁的嵌入（embedding）\n",
    "        x = self.patch_embedding(images)\n",
    "        # 添加位置编码\n",
    "        x = self.positional_encoding(x)\n",
    "        # 编码\n",
    "        x = self.transformer_encoder(x)\n",
    "        # 分类的线性层\n",
    "        x = self.classifier(x[:,0])\n",
    "        return x"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "c34a2a74-574a-4adb-8bbf-574078ccbfdc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T01:32:57.564021Z",
     "start_time": "2025-10-16T01:32:57.561111Z"
    }
   },
   "source": [
    "d_model = 9 # 嵌入的维度9\n",
    "n_classes = 10 # 类别数量为10\n",
    "img_size = (32,32) # 图片大小为32x32\n",
    "patch_size = (16,16) # 补丁的大小是16x16\n",
    "n_channels = 1 # 灰度图片通道数量为1\n",
    "n_heads = 3 # 3个注意力头\n",
    "n_layers = 3 # 3层编码器\n",
    "batch_size = 128 # 每个批次128张图片\n",
    "epochs = 5 # 训练5个epoch\n",
    "alpha = 0.005 # 学习率5e-3"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "8044def3-ded8-4f46-87f2-2055add99565",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T01:33:02.637212Z",
     "start_time": "2025-10-16T01:33:02.596936Z"
    }
   },
   "source": [
    "transform = T.Compose([\n",
    "    T.Resize(img_size), # 28x28 --> 32x32\n",
    "    T.ToTensor() # 转换成torch.tensor\n",
    "])\n",
    "\n",
    "train_set = MNIST(\n",
    "    root=\"./../datasets\", train=True, download=True, transform=transform\n",
    ")\n",
    "test_set = MNIST(\n",
    "    root=\"./../datasets\", train=False, download=True, transform=transform\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_set, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_set, shuffle=False, batch_size=batch_size)"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "cc4ea875-698f-49fb-91fc-db5ec86be502",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T01:34:00.896542Z",
     "start_time": "2025-10-16T01:33:04.910693Z"
    }
   },
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "ViT = VisionTransformer(\n",
    "    d_model,\n",
    "    n_classes,\n",
    "    img_size,\n",
    "    patch_size,\n",
    "    n_channels,\n",
    "    n_heads,\n",
    "    n_layers\n",
    ").to(device)\n",
    "\n",
    "optimizer = Adam(ViT.parameters(), lr=alpha)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    training_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # 取出图像和对应的标签\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # 前向传播\n",
    "        outputs = ViT(inputs)\n",
    "        # 交叉熵损失\n",
    "        loss = criterion(outputs, labels)\n",
    "        # 求导数\n",
    "        loss.backward()\n",
    "        # 梯度下降\n",
    "        optimizer.step()\n",
    "\n",
    "        training_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{epochs} loss: {training_loss  / len(train_loader) :.3f}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 loss: 1.784\n",
      "Epoch 2/5 loss: 1.664\n",
      "Epoch 3/5 loss: 1.630\n",
      "Epoch 4/5 loss: 1.557\n",
      "Epoch 5/5 loss: 1.548\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "ac136de4-66bc-454e-99bd-2fd86ef0ecbe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T01:34:08.778226Z",
     "start_time": "2025-10-16T01:34:07.512571Z"
    }
   },
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = ViT(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    print(f'\\n预测准确率: {100 * correct // total} %')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "预测准确率: 92 %\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T01:36:03.677125Z",
     "start_time": "2025-10-16T01:36:03.666155Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 训练完成后保存模型权重\n",
    "torch.save(ViT.state_dict(), 'vit_mnist_weights.pth')\n",
    "print(\"模型权重已保存\")"
   ],
   "id": "7fb8f4a72e47de8e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型权重已保存\n"
     ]
    }
   ],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
